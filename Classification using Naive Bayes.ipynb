{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('employees_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Allocate ‘Age’, ‘BusinessTravel’, ‘MonthlyIncome’ and ‘JobSatisfaction’ attributes as input and 'Attrition' as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ds.iloc[:, [0, 1, 2, 3]].values  #Age, BusinessTravel, MonthlyIncome, JobSatisfaction\n",
    "y = ds.iloc[:, 23].values  #Attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41, 'Travel_Rarely', 5993, 4],\n",
       "       [49, 'Travel_Frequently', 5130, 2],\n",
       "       [37, 'Travel_Rarely', 2090, 3],\n",
       "       ...,\n",
       "       [27, 'Travel_Rarely', 6142, 2],\n",
       "       [49, 'Travel_Frequently', 5390, 2],\n",
       "       [34, 'Travel_Rarely', 4404, 3]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No', 'Yes', ..., 'No', 'No', 'No'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Use LabelEncoder to encode categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "x[:, 1] = labelencoder.fit_transform(x[:, 1])  #Apply label encoder to BusinessTravel column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41, 2, 5993, 4],\n",
       "       [49, 1, 5130, 2],\n",
       "       [37, 2, 2090, 3],\n",
       "       ...,\n",
       "       [27, 2, 6142, 2],\n",
       "       [49, 1, 5390, 2],\n",
       "       [34, 2, 4404, 3]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Split the data into training and test sets with the appropriate proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 80:20 as train:test proportion\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1176, 4), (294, 4), (1176,), (294,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape , y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Normalize the data using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)   \n",
    "\n",
    "# For x_test, no need another fit, just transform. \n",
    "# Since fit was already applied for the first time to x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.3389367 ,  0.595307  ,  2.41725694,  1.14972558],\n",
       "       [ 0.9043263 ,  0.595307  , -0.91612115,  1.14972558],\n",
       "       [ 0.35255307,  0.595307  ,  0.41020041, -1.57257768],\n",
       "       ...,\n",
       "       [ 0.68361701,  0.595307  ,  0.29395671,  1.14972558],\n",
       "       [ 0.13184377,  0.595307  , -0.72026428,  0.24229116],\n",
       "       [ 0.35255307,  0.595307  ,  0.68736435, -0.66514326]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08886552, -2.37113807,  0.74559207,  1.14972558],\n",
       "       [-0.41992946,  0.595307  , -0.45284024, -0.66514326],\n",
       "       [-0.19922017, -0.88791553, -0.39058952,  0.24229116],\n",
       "       ...,\n",
       "       [-0.64063875,  0.595307  , -0.06070303,  0.24229116],\n",
       "       [ 0.13184377,  0.595307  ,  0.01996883,  0.24229116],\n",
       "       [ 0.35255307,  0.595307  ,  0.01213456, -1.57257768]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Fit and predict results using the Naïve Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No'], dtype='<U3')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - Evaluate the results using confusion matrix and calculate the prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[241,   4],\n",
       "       [ 48,   1]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8231292517006803"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 - Briefly discuss the results and findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:\n",
    "\n",
    "1 - From the Confusion Matrix obtained in Section B8, it is observed that TP = 241, FP = 48, TN = 1, and FN = 4. This leads to an accuracy of 82%, which is quite decent.\n",
    "\n",
    "2 - Note that smoothing technique was not applied throughout the whole process, which means that IF categorical variable has a category in test data set but not observed in training data set, then the set up model will not be able to make a prediction. This case is known as \"Zero Frequency\".\n",
    "\n",
    "3 - Another thing to note is that Naive Bayes assumes that predictors are independent. However, it cannot be guaranteed that \"Age\", \"BusinessTravel\", \"MonthlyIncome\", and \"JobSatisfaction\" are completely independent. If they are indeed not, then the predictions made by the set up model are arguable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
